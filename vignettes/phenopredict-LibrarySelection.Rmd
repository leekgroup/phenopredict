---
title: "Library Prediction"
author: "Shannon E. Ellis"
output: 
  BiocStyle::html_document
vignette: >
  %\VignetteIndexEntry{recount quick start guide}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}  
---

```{r vignetteSetup, echo=FALSE, message=FALSE, warning = FALSE}
## Track time spent on making the vignette
startTime <- Sys.time()
```
# Load libraries

```{r load-packages, message = FALSE, warning = FALSE}
## load libraries
library(devtools)
document("/users/sellis/phenopredict")
library('phenopredict')
library(rtracklayer)
library(recount)
library(genefilter)
library(plyr)

## Set colors
## import colors to use
  bright= c(red=rgb(222,45,38, maxColorValue=255), #de2d26
            pink=rgb( 255, 102, 153, maxColorValue=255), #ff6699
            orange=rgb(232,121,12, maxColorValue=255),   #e8790c
            yellow=rgb(255,222,13, maxColorValue=255), #ffde0d          
            green=rgb(12,189,24, maxColorValue=255),  #0cbd18           
            teal=rgb(59,196,199, maxColorValue=255), #3bc4c7
            blue=rgb(58,158,234, maxColorValue=255), #3a9eea
            purple=rgb(148,12,232, maxColorValue=255)) #940ce8  
```

```{r load-function, message = FALSE, warning = FALSE}
## to chose max value, but assign NA if max is 0
which.highest <- function(x){
    if(max(x)!=0){
        return(which.max(x))
    }else{
        return(length(tiss)+1)
    }
}
```

```{r load-sra-metadata, message = FALSE, warning = FALSE}


```

# Select regions from training data

```{r 'select-regions', message = FALSE, warning = FALSE}
library(GenomicRanges)
if(!file.exists("/dcl01/leek/data/sellis/barcoding/data/SRA_inputdata_LibrarySelection.Rdata")){
  #### SRA data [generated in merge_bwtool_by_chunk.R]
  ## which chunk regions are in [chunk_grp]
  load('/dcl01/leek/data/sellis/barcoding/data/chunk_grp.Rdata')
  ## region information [regions]
  load('/dcl01/leek/data/sellis/barcoding/data/regions-cut0.5.Rdata')
  reg = regions
  rm(regions)
  ## add chunk information to all 1,187,643 regions
  reg$chunkname <- chunk_grp

  ## remove noncanoncial chromosomes
  chunk_name = table(chunk_grp) %>% names()
  chunk_name = grep("chrUn", chunk_name,invert=T,val=T)
  chunk_name = grep("random", chunk_name,invert=T,val=T)
  chunk_name = grep("EBV", chunk_name,invert=T,val=T)
  chunk_name = grep("chrM", chunk_name,invert=T,val=T)

  # selecting training and test set samples
 load(paste0('/dcl01/leek/data/gtex_work/runs/sra/DER_analysis/coverageMatrix/ers_gtex/coverageMatrix-cut0.5-', chunk_name[1], '.Rdata'))
  set.seed(1567)
  samples_to_use<-sample(colnames(coverageMatrix), ncol(coverageMatrix)/2 )
  keep = colnames(coverageMatrix) %in% samples_to_use

## load SRA metadata
### Load in SRA metadata
load('/dcl01/leek/data/recount-website/metadata/metadata_sra.Rdata')
metadata <- metadata[!is.na(metadata$bigwig_path), ]
sra_meta = metadata
rm(metadata)


### Keep only the good SRA and get them in the same order
mm = match(colnames(coverageMatrix),sra_meta$run)
sra_meta = sra_meta[mm,]
pd = read_csv("https://raw.githubusercontent.com/nellore/runs/master/sra/v2/hg38/SraRunInfo.csv")
sra_meta = left_join(as.data.frame(sra_meta),pd,by=c("run"="Run","sample"="Sample"))
## remove rogue spaces and dashes from phenotype of interest
sra_meta[,phenot]<-sub("-","",sra_meta[,phenot])

  ## have to go through and select regions from each chunk that specify library prep
	regions_split <- split(reg, reg$chunkname)
	phenot="LibrarySelection"

	xx <- lapply(chunk_name, function(chunk_name) {
	     message(paste(Sys.time(), 'processing', chunk_name))
	      
	     ## Load coverage matrix for each chunk [coverageMatrix]
	     load(paste0('/dcl01/leek/data/gtex_work/runs/sra/DER_analysis/coverageMatrix/ers_gtex/coverageMatrix-cut0.5-', chunk_name, '.Rdata'))

	      ## Load regions included in the chunk [regions_subset]
	     load(paste0('/dcl01/leek/data/gtex_work/runs/sra/DER_analysis/coverageMatrix/ers_gtex/regions_', chunk_name, '-cut0.5.Rdata'))

	     ## split into training and test 
	     sra_training = coverageMatrix[,keep]
	     sra_test = coverageMatrix[,!keep]

	     sra_meta_training <<- sra_meta[keep,]
	     sra_meta_test <<- sra_meta[!keep,]

	     ## quick and dirty test to minimize number of regions input 
	     if(length(names(table(sra_meta_training[,phenot])))==2){
	     	subs = rowttests(sra_training,factor(sra_meta_training[,phenot]))
	     }else(
	     	subs = rowFtests(sra_training,factor(sra_meta_training[,phenot]))
	     )

	     cutoff = quantile(subs$p.value,0.05)
	     tokeep<-subs$p.value<cutoff
	    sra_training = log2(sra_training[tokeep,]+1)
	    sra_test = log2(sra_test[tokeep,]+1)
		regions_subset = regions_subset[tokeep]

	      ## Select regions associated with LibraryPrep
   		 inputdata<-select_regions(expression=sra_training, regiondata=regions_subset ,phenodata=sra_meta_training, phenotype=phenot, covariates=NULL,type="factor", numRegions=10)

   		new<-extract_data(newexpression=sra_test, newregiondata=regions_subset, predictordata=inputdata)
    	inputdata$sra_test <- new
	     
	      ## Finish
	      return(inputdata)
	  })
	names(xx) <- chunk_name

	  ## compile the subset of regions into a single object
	  merge_input<- merge_input(inputdata_list=xx)

	#remove "id"column
	merge_input$covmat = dplyr::select(merge_input$covmat, -(.id))

	  save(merge_input,file='/dcl01/leek/data/sellis/barcoding/data/SRA_inputdata_LibrarySelection.Rdata')
	}else{
	  load('/dcl01/leek/data/sellis/barcoding/data/SRA_inputdata_LibrarySelection.Rdata')
	}

# taking a look at output of select_regions)
dim(merge_input$covmat)
merge_input$regiondata

```


# Build predictor in training data

```{r 'build-predictor', message = FALSE, warning = FALSE}
if(!file.exists("/dcl01/leek/data/sellis/barcoding/data/merge_input_LibrarySelection_nocovars.rda")) {
	predictor<-build_predictor(inputdata=merge_input ,phenodata=sra_meta_training, phenotype=phenot,		 
		covariates=NULL,type="factor", numRegions=40)
	save(predictor, file= "/dcl01/leek/data/sellis/barcoding/data/build_predictor_LibrarySelection_nocovars.rda")
}else{
	load('/dcl01/leek/data/sellis/barcoding/data/build_predictor_LibrarySelection_nocovars.rda')
}

#number of probes used for prediction
length(predictor$trainingProbes)

#this contains the coefficient estimates used for prediction. 
# the number of rows corresponds to the number of sites used for prediction
# while the columns corresponds to the number of categories of your phenotype.
dim(predictor$coefEsts)

```

# Resubstitution Error

```{r 'test-predictor', message = FALSE, warning = FALSE}
predictions_test <-test_predictor(inputdata=merge_input ,phenodata=sra_meta_training, phenotype=phenot, 
    covariates=NULL,type="factor",predictordata=predictor )

# get summary of how prediction is doing
predictions_test$summarized
```

# Extract data for prediction set

```{r 'extract-data', message = FALSE, warning = FALSE}
# looking at the input data for extract_data
if(!file.exists("/dcl01/leek/data/sellis/barcoding/data/merge_input_SMTS_nocovars.rda")) {

	purrr::map(xx, function(x){return(x$sra_test)}) %>% ldply(., data.frame) -> sra_test_covmat
	#remove "id"column
	sra_test_covmat= dplyr::select(sra_test_covmat, -(.id))
	colremove<-grep("regiondata", colnames(sra_test_covmat))
	sra_test_covmat= sra_test_covmat[, -colremove]

	  sra_test_inputdata=list()
	  ov <- findOverlaps(predictor$regiondata,merge_input$regiondata)
	  index_regions <- subjectHits(ov)
	  #reorder GRanges objects
	  sra_test_inputdata$covmat  <- sra_test_covmat[index_regions,]
	  sra_test_inputdata$regiondata <- merge_input$regiondata[index_regions]

	save(sra_test_inputdata, file= "/dcl01/leek/data/sellis/barcoding/data/sra_test_inputdata_LibSelection_nocovars.rda")
}else{
	load('/dcl01/leek/data/sellis/barcoding/data/sra_test_inputdata_LibSelection_nocovars.rda')
}
```

# Predict Library Type

```{r 'predict-phenotype', message = FALSE, warning = FALSE}
predictions<-predict_pheno(inputdata_test= sra_test_inputdata, phenodata=sra_meta_training, phenotype=phenot, covariates=NULL,type="factor", predictordata = predictor)

#since we know the truth here, let's check and see how we're doing:
 
  actual = sra_meta_test[,phenot]

  #define predicted
  predicted = predictions

  #summarize data
	number_match <- sum(predicted==actual)
	perc_correct = sum(predicted==actual)/length(actual)
	number_sites = nrow(predictor$coefEsts)

	summarized = cbind(number_sites,number_match, perc_correct)
	colnames(summarized) <- c("sites_tested", "number_correct", "percent_correct")
 
 #compare predictions to known sex
 summarized

```

```{r 'region-information', message = FALSE, warning = FALSE}
## Get required information for the plots
txdb <- GenomicFeatures::makeTxDbFromGFF('ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.annotation.gff3.gz', format = 'gff3', organism = 'Homo sapiens')
tx<-annotateTranscripts(txdb, annotationPackage = NULL, by = c("tx","gene"), codingOnly=FALSE, verbose = TRUE, requireAnnotation = FALSE)
output<-matchGenes(predictor$regions, tx, type = c("any", "fiveprime"), promoterDist = 2500, skipExons = FALSE, verbose = TRUE)
output
save(output, file= "/dcl01/leek/data/sellis/barcoding/output/LibSelection_regions.rda")
```

# Vignette information

```{r reproducibility}
## Time spent creating this report:
diff(c(startTime, Sys.time()))

## Date this report was generated
message(Sys.time())

## Reproducibility info
options(width = 120)
devtools::session_info()
```

Code for creating the vignette

```{r createVignette, eval=FALSE}
## Create the vignette
library('rmarkdown')
system.time(render('/users/sellis/phenopredict/vignettes/phenopredict-LibrarySelection.Rmd', 'BiocStyle::html_document'))

## Extract the R code
library('knitr')
knit('/users/sellis/phenopredict/vignettes/phenopredict-LibrarySelection.Rmd', tangle = TRUE)
```


